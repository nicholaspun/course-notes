% !TeX root = ../cs487.tex

\section{Fast Division with Remainder and Newton Iteration}

(See \Cref{sec:multiplication-time} for notes on Multiplication time)

\subsection{Fast Division with Remainder}
\ul{Goal}: Given two polynomials: 
\begin{align*}
    a(x) &= a_nx^n + a_{n-1}x^{n-1} + \ldots + a_1x + a_0 \in \F[x] \\
    b(x) &= b_mx^m + b_{m-1}x^{m-1} + \ldots + b_1x + b_0 \in \F[x].
\end{align*} 
with $a_n, b_m \neq 0$, $b$ monic, and $m \leq n$, find $q(x)$ and $r(x)$ such that $a(x) = q(x)b(x) + r(x)$, $\deg r < \deg b$.

\subsubsection{Reversions}
To solve the above problem, we'll need a new operation called \ul{reversion}. 

Given $a(x) = a_nx^n + a_{n-1}x^{n-1} + \ldots + a_1x + a_0 \in \F[x]$, we define the reversion of $a$, denoted $\rev(a)$ or $\rev_n(a)$ to be the following procedure:
\begin{enumerate}
    \item Substitute $x$ with $\frac{1}{y}$, then
    \item Multiply by $y^n$.
\end{enumerate} 
This gives:
\begin{equation}
    \begin{aligned}
        \rev(a) = \rev_n(a) &:= y^na\left(\frac{1}{y}\right) \\
        &= y^n\left(a_0 + a_1\left(\frac{1}{y}\right) + \ldots + a_n\left(\frac{1}{y^n}\right)\right) \\
        &= y^na_0 + y^{n-1}a_1 + \ldots + a_n
    \end{aligned}
\end{equation}
So, we have reversed the ordering of the coefficients.

\begin{remark}
    $\rev\left(\rev\left(a\right)\right) = a$
\end{remark}

\begin{note}
    Reversions don't cost any ring operations. For example, if the coefficients were stored as an array, then a reversion is just a reversal of the array. 
\end{note}

\subsubsection{Back to Fast Division}
Using the idea of reversions, let's rewrite our goal.
The reversion of $a(x) = q(x)b(x) + r(x)$ is:
\begin{align*}
    \rev_n(a) = y^na\left(\frac{1}{y}\right) &= y^n\left(q\left(\frac{1}{y}\right)b\left(\frac{1}{y}\right) + r\left(\frac{1}{y}\right)\right) \\
    &= y^n\left(q\left(\frac{1}{y}\right)\right)
    y^n\left(b\left(\frac{1}{y}\right)\right) + 
    y^n\left(r\left(\frac{1}{y}\right)\right) \\
    &= \rev_{n-m}(q)\rev_m(b) + y^{n-m+1}\rev_{m-1}(r)
\end{align*}
For the last step: $\deg b = m$, so $\deg q = n - m$.
Further, since $\deg r < \deg b$, $\deg r$ is at most $m-1$.

And, if we take the equation modulo $y^{n - m + 1}$, this gives:
\begin{equation}\label{eq:lec7-fast-division-new-goal}
    \rev_n(a) = \rev_{n-m}(q)\rev_m(b) \pmod{y^{n-m+1}}
\end{equation}
\ul{We revise our goal}: Solve \Cref{eq:lec7-fast-division-new-goal} for the unknown $\rev_{n-m}(q)$

\subsection{Newton Iteration}
To solve \Cref{eq:lec7-fast-division-new-goal}, we want to take the inverse of $\rev_m(b)$:
\begin{equation}
    \rev_{n-m}(q) = \rev_n(a)\rev_m(b)^{-1} \pmod{y^{n-m+1}}
\end{equation}
\ul{Generalizing this problem a bit}: Given a function $g$ and $k \in \N$, we want to find a function $h$ so that $gh \equiv 1 \mod{x^k}$.

The main idea is to do this iteratively using Newton's method.
Recall that Newton's method calculates a sequence $h_0, h_1, h_2, \ldots$ by using the formula:
\begin{equation}
    h_{i + 1} = h_i - \frac{\phi(h_i)}{\phi'(h_i)}
\end{equation}
Toying around with the function for $\phi$, we find that $\phi(h) = \frac{1}{h} - g$ will work for us since $1/g$ is a root of $\phi$.
Indeed, $\phi(1/g) = \frac{1}{1/g} - g = g - g = 0$.

Suppose we already have $h_i$, let's perform one iteration of newton's method with the above $\phi$:
\begin{align*}
    h_{i + 1} &= h_i - \frac{\phi(h_i)}{\phi'(h_i)} \\
    &= h_i - \frac{\frac{1}{h_i} - g}{-\frac{1}{h_i^2}} \\
    &= h_i + h_i - gh_i^2 \\
    &= 2h_i - gh_i^2
\end{align*}
How fast does this converge to our desired modulus $x^k$?
Observe that $h_i$ is squared in each iteration, so our precision is doubled in each step.

We summarize this in the following theorem:
\begin{theorem}{}{}
    Let $h_0, h_1, h_2, \ldots \in \F[x]$ be such that $\deg h_i < 2^i$ and $gh_i \equiv 1 \pmod{x^{2^i}}$.
    Then, $h_0 = 1$ and $h_{i + 1} \equiv 2h_i - gh_i^2 \pmod{x^{2^{i+1}}}$ for $i > 0$
\end{theorem}
And, this yields the following algorithm:

\begin{algorithm}[H]
    \caption{Quadratic Newton Iteration}\label{alg:quadratic-newton-iteration}
    
    \textbf{Input}: $g \in \F[x]$ monic and $n = 2^r$
    
    \textbf{Output}: $h \in \F[x]$ such that $gh \equiv 1 \pmod{x^n}$

    \BlankLine
    \nl $h_0 :=  1$

    \nl \For{$i = 0, 1, \ldots, r$}{
        $h_{i + 1} = 2h_i - gh_i^2 \pmod{x^{2^{i + 1}}}$
    }
\end{algorithm}

\begin{theorem}{Time Complexity of \Cref{alg:quadratic-newton-iteration}}{lec7-time-complexity-quadratic-newton-iteration}
    If $n = 2^r$, then $h_r \equiv g^{-1} \pmod{x^n}$ can be computed in $\bigO(M(n))$ field operations    
\end{theorem}
\begin{proof}
    Computing $h_{i + 1}$ requires at most $2M(2^{i + 1}) + 2 \cdot 2^{i + 1}$ field operations. (Polynomial multiplication, scalar multiplication and subtraction).
    Then, the total cost is:
    \begin{align*}
        &2\sum_{i = 0}^{r - 1} \left(M\left(2^{i + 1}\right) + 2^{i + 1}\right) \\
        &= \left(2\sum_{i = 0}^{r - 1} M\left(2^{i + 1}\right)\right) + \left(4\sum_{i = 0}^{r - 1}2^i\right) \\
        &\leq \left(2\sum_{i = 0}^{r - 1} M\left(2^{i + 1}\right)\right) + 4n \\
        &\leq 2M\left(2^r\right)\sum_{i = 0}^{r - 1} \frac{1}{2^{r - i}} + 4n \qquad \left(\text{since $M(2^i) \leq \frac{M(2^r)}{2^{r - i}}$ by superlinearity}\right) \\
        &\leq 2M\left(2^r\right)\sum_{i \geq 0} \frac{1}{2^i} + 4n \\
        &\in \bigO\left(M\left(2^r\right)\right) + \bigO(n) \\
        &\in \bigO\left(M(n)\right)
    \end{align*}
\end{proof}

\subsection{Completing Fast Division with Remainder}
We now have the necessary components to complete the algorithm for Fast Division with Remainder:

\begin{algorithm}[H]
    \caption{Fast Division with Remainder}\label{alg:fast-division-with-remainder}
    
    \textbf{Input}: Two polynomials: 
    \begin{itemize}
        \item $a(x) = a_nx^n + a_{n-1}x^{n-1} + \ldots + a_1x + a_0 \in \F[x]$
        \item $b(x) = b_mx^m + b_{m-1}x^{m-1} + \ldots + b_1x + b_0 \in \F[x]$
    \end{itemize} 
    with $a_n, b_m \neq 0$, $b$ monic, and $m \leq n$
    
    \textbf{Output}: $q(x)$ and $r(x)$ such that $a(x) = q(x)b(x) + r(x)$, $\deg r < \deg b$.

    \BlankLine
    \nl Compute $\rev(a)$

    \nl Compute $\rev(b)^{-1}$ to precision $x^{n - m + 1}$ using \Cref{alg:quadratic-newton-iteration}

    \nl Compute $\rev(q) = \rev(a)\cdot\rev(b)^{-1} \pmod{x^{n - m + 1}}$

    \nl $q \leftarrow \rev\left(\rev(q)\right)$

    \nl $r \leftarrow a - q \cdot b$
\end{algorithm}

\begin{corollary}{}{}
    Let $a, b \in \F[x]$ with $\deg a = n, \deg b = m, n \geq m$. Then, $q = a \quo b$ can be computed in $M(n - m)$ field ops
\end{corollary}
\begin{proof}
    By \Cref{th:lec7-time-complexity-quadratic-newton-iteration}
\end{proof}

\begin{corollary}{}{}
    For polynomials of degree at most $n$ in $\F$, division with remainder requires at most $\bigO(M(n))$ operations.
\end{corollary}
\begin{proof}
    Computing $q$ uses at most $M(n - m)$ field ops and computing $r$ uses at most $\bigO(M(n))$ field ops
\end{proof}

\subsection{Concluding Remarks}
\begin{theorem}{Existence and Uniqueness of Inverse}{}
    Let $g = g_0 + g_1x + g_2x^2 + \ldots \in F[[x]]$ have constant coefficient $g_0 = 1$.
    For any $k \in \Z_{> 0}$, there exists a unique $b \in F[x]$ with $\deg b < k$ such that $bg \equiv 1 \pmod{x^k}$
\end{theorem}
\begin{proof}
    We work in $\mathrm{mod}\ x^k$.
    Write $g = 1 + g_1x + \ldots + g_{k-1}x^{k-1} \pmod{x^{k-1}}$ and let $b = b_0 + b_1x + \ldots + b_{k-1}x^{k-1}$.
    Then,
    \begin{equation*}
        bg = (b_0 + b_1x + \ldots + b_{k-1}x^{k-1})(1 + g_1x + \ldots + g_{k-1}x^{k-1}) \equiv 1
    \end{equation*}
    if and only if
    \begin{equation*}
        \begin{blockarray}{crcc}
            & \text{\large B} & &  \\
           \begin{block}{[cccc]}
                1       &           &          &   \\
                b_1     & \ddots    &          &   \\
                \vdots  & \ddots    & \ddots   &   \\
                b_{k-1} & \ldots    & b_1      & 1 \\
            \end{block}
       \end{blockarray}
       \begin{blockarray}{crcc}
            & \text{\large G} & &  \\
            \begin{block}{[cccc]}
                1       &           &          &   \\
                g_1     & \ddots    &          &   \\
                \vdots  & \ddots    & \ddots   &   \\
                g_{k-1} & \ldots    & g_1      & 1 \\
            \end{block}
        \end{blockarray}
        =
        \begin{blockarray}{cclc}
            & & \text{\large I}_k &  \\
           \begin{block}{[cccc]}
                1       &           &          &   \\
                        & \ddots    &          &   \\
                        &           & \ddots   &   \\
                        &           &          & 1 \\
            \end{block}
       \end{blockarray}
    \end{equation*}
    (Note: $BG = I_k$ and $GB = I_k$. This is easy to see since the multiplication of the polynomials is commutative)

    if and only if
    \begin{equation*}
        G
        \begin{bmatrix}
            1 \\ b_1 \\ \vdots \\ b_{k-1}
        \end{bmatrix}
        =
        \begin{bmatrix}
            1 \\ 0 \\ \vdots \\ 0
        \end{bmatrix}
    \end{equation*}
    And this system has a unique solution for $b$.
\end{proof}

\begin{note}
    $B$ and $G$ are known as Toeplitz matrices.
\end{note}








